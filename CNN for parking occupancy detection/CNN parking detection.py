# -*- coding: utf-8 -*-
"""Proyecto Optimización.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zXKh0NAKfLSE8AjbBPKyhLa1U6wg8_NY
"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

!unzip '/content/CNRPark-Patches-150x150 (1).zip'

#--------------------- Data Preprocessing --------------------#

#feature training
train_datagen = ImageDataGenerator(
        rescale=1./255,                                                   
        shear_range=0.2,                                                    
        zoom_range=0.2,
        horizontal_flip=True)

#connecting the image augmentation tool to our dataset
train_set = train_datagen.flow_from_directory(
        '/content/A',
        target_size=(64, 64),
        batch_size=32,
        class_mode='binary')

#only rescaling but no transformations
test_datagen = ImageDataGenerator(rescale=1./255)

#connecting to the test data
test_set = test_datagen.flow_from_directory(
        '/content/B',
        target_size=(64, 64),
        batch_size=32,
        class_mode='binary')

#--------------------- Building CNN --------------------#

# initializing CNN 
cnn = tf.keras.models.Sequential()

# Convolution to get the Feature Map
cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape=[64,64,3]))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 ,strides=2))

#Adding a second convolutional layer
cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 ,strides=2))

# Flattening
cnn.add(tf.keras.layers.Flatten())

#Full Connection
cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))

#Output Layer
cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))

#--------------------- Training the CNN --------------------#
#compiling the CNN
cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

#training the CNN on the training set and evaluating it on the test set
historial = cnn.fit(x = train_set, validation_data = test_set, epochs = 25)

import matplotlib.pyplot as plt

plt.xlabel("# Epoch")
plt.ylabel("Precisión validación")
plt.plot(historial.history["val_accuracy"])

#--------------------- Single prediction with CNN --------------------#

test_image = image.load_img('/content/prueba.jfif', target_size = (64, 64))
# to convert image in pii format into a numpy array format
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)

# cnn prediction on the test image
result = cnn.predict(test_image)

# getting the results encoding
print(train_set.class_indices)

#prediction for the single image/element from the batch
if result[0][0] == 1:
   prediction = 'Vacio'
else:
   prediction = 'Lleno'

print(prediction)

#--------------------- Prediction of a set of images with CNN --------------------#

path = '/content/B/free'
contenido = os.listdir(path)

n=0
vacios=[]
for i in range(1,1000):
  dir = '/content/B/free/' + contenido[i]
  test_image = image.load_img(dir, target_size = (64, 64))
  test_image = image.img_to_array(test_image)
  test_image = np.expand_dims(test_image, axis = 0)
  result = cnn.predict(test_image)
  if result[0][0] == 1:
    prediction = 'Vacio'
    vacios.append(dir)
  else:
    prediction = 'Lleno'
    n+=1
  print(prediction)

print(n)

#--------------------- Showing the images that the CNN does not predict good --------------------#
for i in range(1,len(vacios)):
  im = mpimg.imread(vacios[i])
  plot = plt.imshow(im)
  plt.show()
